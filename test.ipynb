{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/s\\\\abd\\\\abc\\\\d'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('E:/s', 'abd', 'abc', 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ses01F_impro01_F000.wav',\n",
       " 'Ses01F_impro01_F001.wav',\n",
       " 'Ses01F_impro01_F002.wav',\n",
       " 'Ses01F_impro01_F003.wav',\n",
       " 'Ses01F_impro01_F004.wav',\n",
       " 'Ses01F_impro01_F005.wav',\n",
       " 'Ses01F_impro01_F006.wav',\n",
       " 'Ses01F_impro01_F007.wav',\n",
       " 'Ses01F_impro01_F008.wav',\n",
       " 'Ses01F_impro01_F009.wav',\n",
       " 'Ses01F_impro01_F010.wav',\n",
       " 'Ses01F_impro01_F011.wav',\n",
       " 'Ses01F_impro01_F012.wav',\n",
       " 'Ses01F_impro01_F013.wav',\n",
       " 'Ses01F_impro01_F014.wav',\n",
       " 'Ses01F_impro01_F015.wav',\n",
       " 'Ses01F_impro01_M000.wav',\n",
       " 'Ses01F_impro01_M001.wav',\n",
       " 'Ses01F_impro01_M002.wav',\n",
       " 'Ses01F_impro01_M003.wav',\n",
       " 'Ses01F_impro01_M004.wav',\n",
       " 'Ses01F_impro01_M005.wav',\n",
       " 'Ses01F_impro01_M006.wav',\n",
       " 'Ses01F_impro01_M007.wav',\n",
       " 'Ses01F_impro01_M008.wav',\n",
       " 'Ses01F_impro01_M009.wav',\n",
       " 'Ses01F_impro01_M010.wav',\n",
       " 'Ses01F_impro01_M011.wav',\n",
       " 'Ses01F_impro01_M012.wav',\n",
       " 'Ses01F_impro01_M013.wav']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"E:\\\\Download\\\\IEMOCAP_full_release_withoutVideos\\\\IEMOCAP_full_release\\\\Session1\\\\sentences\\\\wav\\\\Ses01F_impro01\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asbdiasf'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"asbdiasf.wav\"[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.mfcc_extraction import IEMOCAP_Dataset\n",
    "\n",
    "ROOT = \"E:\\\\Download\\\\IEMOCAP_full_release_withoutVideos\\\\IEMOCAP_full_release\"\n",
    "iemocap = IEMOCAP_Dataset(root=ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ang', 'dis', 'exc', 'fea', 'fru', 'hap', 'neu', 'oth', 'sad',\n",
       "       'sur', 'xxx'], dtype='<U3')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocap.LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Download\\\\IEMOCAP_full_release_withoutVideos\\\\IEMOCAP_full_release\\\\Session1\\\\sentences\\\\wav\\\\Ses01F_impro01\\\\Ses01F_impro01_F000.wav'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocap.utterance_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10039"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iemocap.utterance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10039"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iemocap.label_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 31 -31 -23 ... -15 -11 -42]\n",
      "[0.0000000e+00 6.2500000e-05 1.2500000e-04 ... 1.3822500e+00 1.3823125e+00\n",
      " 1.3823750e+00]\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import python_speech_features as psf\n",
    "\n",
    "PATH = iemocap.utterance_paths[1]\n",
    "with wave.open(PATH, 'r') as f:\n",
    "    nchannels, sampwidth, framerate, wav_length = f.getparams()[:4]\n",
    "    data = np.frombuffer(f.readframes(wav_length), dtype=np.short)\n",
    "    print(data)\n",
    "    time = np.arange(0,wav_length) * (1.0/framerate)\n",
    "    print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(137, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(137, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mel_spec = psf.logfbank(data, framerate, nfilt=40)\n",
    "delta1 = psf.delta(mel_spec, 2)\n",
    "delta2 = psf.delta(delta1, 2)\n",
    "display(mel_spec.shape)\n",
    "display(delta1.shape)\n",
    "display(delta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 3, 40)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack((mel_spec, delta1, delta2), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ses01'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Ses01F_impro01_F000'[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, array([[[2, 2, 4],\n",
       "                  [0, 2, 1],\n",
       "                  [0, 3, 0]],\n",
       "\n",
       "                 [[1, 2, 0],\n",
       "                  [2, 0, 3],\n",
       "                  [0, 4, 3]],\n",
       "\n",
       "                 [[0, 1, 3],\n",
       "                  [0, 2, 3],\n",
       "                  [3, 1, 0]]])], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.randint(5, size=(3,3,3))\n",
    "b = 1\n",
    "\n",
    "np.array((b, a), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.load(\"E:\\\\Download\\\\IEMOCAP_full_release_withoutVideos\\\\data\\\\train\\\\Ses01F_impro01_F000.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 3, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3, 40)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(sample[1], ((0, 106), (0, 0), (0, 0))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([194, 3, 40])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sample_data = torch.tensor(sample[1])\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 3, 40])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.pad(sample_data, (0, 0, 0, 0, 0, 300 - 194)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/IEMOCAP.pkl\", \"rb\") as f:\n",
    "\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 300, 40, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 300, 40, 3)\n",
      "(1200, 1)\n",
      "(420, 300, 40, 3)\n",
      "(259, 1)\n",
      "(436, 300, 40, 3)\n",
      "(298, 1)\n",
      "(436, 1)\n",
      "(420, 1)\n",
      "(259,)\n",
      "(298,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    \n",
    "    print(data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 300, 40, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class acrnn(nn.Module):\n",
    "    def __init__(self, num_classes=4, is_training=True,\n",
    "                 L1=128, L2=256, cell_units=128, num_linear=768,\n",
    "                 p=10, time_step=150, F1=64, dropout_keep_prob=1):\n",
    "        super(acrnn, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.is_training = is_training\n",
    "        self.L1 = L1\n",
    "        self.L2 = L2\n",
    "        self.cell_units = cell_units\n",
    "        self.num_linear = num_linear\n",
    "        self.p = p\n",
    "        self.time_step = time_step\n",
    "        self.F1 = F1\n",
    "        self.dropout_prob = 1 - dropout_keep_prob\n",
    "\n",
    "        # tf filter : [filter_height, filter_width, in_channels, out_channels]\n",
    "        self.conv1 = nn.Conv2d(3, self.L1, (5, 3), padding=(2, 1))       # [5, 3,   3, 128]  \n",
    "        self.conv2 = nn.Conv2d(self.L1, self.L2, (5, 3), padding=(2, 1)) # [5, 3, 128, 256]\n",
    "        self.conv3 = nn.Conv2d(self.L2, self.L2, (5, 3), padding=(2, 1)) # [5, 3, 256, 256]\n",
    "        self.conv4 = nn.Conv2d(self.L2, self.L2, (5, 3), padding=(2, 1)) # [5, 3, 256, 256]\n",
    "        self.conv5 = nn.Conv2d(self.L2, self.L2, (5, 3), padding=(2, 1)) # [5, 3, 128, 256]\n",
    "        self.conv6 = nn.Conv2d(self.L2, self.L2, (5, 3), padding=(2, 1)) # [5, 3, 128, 256]\n",
    "\n",
    "        self.linear1 = nn.Linear(self.p*self.L2, self.num_linear) # [10*256, 768]\n",
    "        self.bn = nn.BatchNorm1d(self.num_linear)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(0.01)\n",
    "        self.dropout = nn.Dropout2d(p=self.dropout_prob)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=self.num_linear, hidden_size=self.cell_units, \n",
    "                            batch_first=True, num_layers=1, bidirectional=True) \n",
    "\n",
    "        # for attention\n",
    "        self.a_fc1 = nn.Linear(2*self.cell_units, 1)  \n",
    "        self.a_fc2 = nn.Linear(1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(2*self.cell_units, self.F1) # [2*128, 64]\n",
    "        self.fc2 = nn.Linear(self.F1, self.num_classes) # [num_classes]\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        layer1 = self.relu(self.conv1(x))\n",
    "        layer1 = F.max_pool2d(layer1, kernel_size=(2, 4), stride=(2, 4))   # [1,2,4,1], padding = 'valid'\n",
    "        layer1 = self.dropout(layer1)\n",
    "\n",
    "        layer2 = self.relu(self.conv2(layer1))\n",
    "        layer2 = self.dropout(layer2)\n",
    "        \n",
    "        layer3 = self.relu(self.conv3(layer2))\n",
    "        layer3 = self.dropout(layer3)\n",
    "\n",
    "        layer4 = self.relu(self.conv4(layer3))\n",
    "        layer4 = self.dropout(layer4)\n",
    "\n",
    "        layer5 = self.relu(self.conv5(layer4))\n",
    "        layer5 = self.dropout(layer5)\n",
    "\n",
    "        layer6 = self.relu(self.conv6(layer5))\n",
    "        layer6 = self.dropout(layer6)\n",
    "        \n",
    "        # lstm\n",
    "        layer6 = layer6.permute(0, 2, 3, 1)\n",
    "        layer6 = layer6.reshape(-1, self.time_step, self.L2*self.p)        # (-1, 150, 256*10)\n",
    "        layer6 = layer6.reshape(-1, self.L2*self.p)                        # (1500, 2560)\n",
    "\n",
    "        linear1 = self.relu(self.bn(self.linear1(layer6)))                 # [1500, 768]\n",
    "        linear1 = linear1.reshape(-1, self.time_step, self.num_linear)     # [10, 150, 768]\n",
    "        \n",
    "        outputs1, output_states1 = self.rnn(linear1)                       # outputs1 : [10, 150, 128] (B,T,D)\n",
    "\n",
    "        # # attention\n",
    "        v = self.sigmoid(self.a_fc1(outputs1))                  # (10, 150, 1)\n",
    "        alphas = self.softmax(self.a_fc2(v).squeeze())          # (B,T) shape, alphas are attention weights\n",
    "        gru = (alphas.unsqueeze(2) * outputs1).sum(axis=1)      # (B,D)\n",
    "        \n",
    "        # # fc\n",
    "        fully1 = self.relu(self.fc1(gru))\n",
    "        fully1 = self.dropout(fully1)\n",
    "        Ylogits = self.fc2(fully1)\n",
    "        Ylogits = self.softmax(Ylogits)\n",
    "\n",
    "        return Ylogits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 300, 40])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# data_194 = torch.randint(0, 5, size=(10, 194, 40, 3))\n",
    "# data_194.transpose((0, 3, 1, 2))\n",
    "data_194 = torch.tensor(np.random.randint(3, size=(10, 300, 40, 3)).transpose((0, 3, 1, 2))).float()\n",
    "data_194.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp/counterfactual_fairness_emotional_recognition'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.datasets import IEMOCAPSamples\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "PATH = \"data/data\"\n",
    "iemocap_samples = IEMOCAPSamples(PATH)\n",
    "iemocap_loader = DataLoader(iemocap_samples, batch_size=64, collate_fn=iemocap_samples.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1154"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iemocap_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_lengths, y = next(iter(iemocap_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 64, 3, 40])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.float()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:20<00:00,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "min_padded_length = 1000\n",
    "n = 0\n",
    "\n",
    "loader_iterator = iter(iemocap_loader)\n",
    "sample = None\n",
    "\n",
    "for i in tqdm(range(len(iemocap_loader)), total=len(iemocap_loader)):\n",
    "\n",
    "    X, _, _ = next(loader_iterator)\n",
    "    if X.shape[0] < min_padded_length:\n",
    "        min_padded_length = X.shape[0]\n",
    "\n",
    "    if X.shape[0] < 300:\n",
    "        sample = X\n",
    "\n",
    "print(min_padded_length, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 64, 3, 40])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "class ACRNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ACRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Sequential(*[\n",
    "            nn.Conv2d(in_channels=3,   out_channels=128, kernel_size=(5, 3), padding=(2, 1), stride=(2, 2)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(5, 3), padding=(2, 1), stride=(2, 2)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.GELU()\n",
    "        ])\n",
    "\n",
    "        self.linear = nn.Sequential(*[\n",
    "            nn.Linear(2560, 768)\n",
    "        ])\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=768, hidden_size=256, num_layers=4, dropout=0.5, bidirectional=True)\n",
    "\n",
    "        # self.classifier = nn.Sequential(*[\n",
    "        #     nn.Linear(512, 1024),\n",
    "        #     nn.GELU(),\n",
    "        #     nn.Linear(1024, 11),\n",
    "        #     nn.Softmax(dim=2)\n",
    "        # ])\n",
    "\n",
    "        self.a_fc1 = nn.Linear(512, 1)\n",
    "        self.a_fc2 = nn.Linear(1, 1)\n",
    "        self.a_sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.a_softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0),\n",
    "            nn.Linear(512, 11),\n",
    "            nn.Softmax(dim=1)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, X, X_lengths):\n",
    "\n",
    "        X = X.permute((1, 2, 0, 3))\n",
    "        out = self.embedding(X)\n",
    "        out = out.permute((2, 0, 1, 3))\n",
    "\n",
    "        out_shape = out.shape\n",
    "        out = out.reshape((out_shape[0], out_shape[1], -1))\n",
    "        out = self.linear(out)\n",
    "\n",
    "        # packed_out = pack_padded_sequence(out, X_lengths, enforce_sorted=False)\n",
    "        out, (_, _) = self.rnn(out)\n",
    "        # out, lengths = pad_packed_sequence(out)\n",
    "        # out = out.permute(1, 0, 2).reshape((out.shape[0], -1))\n",
    "        # out = self.classifier(out)\n",
    "\n",
    "        out = out.permute(1, 0, 2)\n",
    "        v = self.a_sigmoid(self.a_fc1(out))\n",
    "        alphas = self.a_softmax(self.a_fc2(v).squeeze())\n",
    "        gru = (alphas.unsqueeze(2) * out).sum(axis=1)\n",
    "\n",
    "        out = self.classifier(gru)\n",
    "\n",
    "        # out = torch.stack([out[X_lengths[i] - 1, i, :] for i in range(out.shape[1])])\n",
    "\n",
    "        return out\n",
    "\n",
    "model = ACRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(X, X_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 11])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_reshape = out.reshape((723, 5, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_reshape[0, 1, 79] == out[0, 1, 1, 39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.datasets import IEMOCAPSamples, IEMOCAPSmall\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "PATH = \"data/data\"\n",
    "iemocap_samples = IEMOCAPSmall()\n",
    "iemocap_loader = DataLoader(iemocap_samples, batch_size=64)\n",
    "\n",
    "X, y = next(iter(iemocap_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 300, 40, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp/counterfactual_fairness_emotional_recognition'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"data/IEMOCAP_val.pkl\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 300, 40, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = data[2][:428]\n",
    "valid_data.shape\n",
    "\n",
    "np.save('data/IEMOCAP_valid_data.npy', valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_label = data[1][:428]\n",
    "valid_label.shape\n",
    "\n",
    "np.save('data/IEMOCAP_valid_label.npy', valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_label = data[1][:428]\n",
    "valid_label.shape\n",
    "\n",
    "np.save('data/IEMOCAP_Valid_label.npy', valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pernums_valid = np.ones(428, dtype=int)\n",
    "pernums_valid.shape\n",
    "np.save('data/IEMOCAP_pernums_valid.npy', pernums_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.empty((0, 50))\n",
    "b = np.ones((1, 50))\n",
    "np.vstack((a, b)) == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([2, 2])\n",
    "accuracy_score(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('log/log_20220418_100852_acrnn_ar0.2_ld0.4.pkl', 'rb') as f:\n",
    "    tracker = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f05eca15d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list(range(len(tracker.training_loss))), tracker.training_loss, label=\"training loss\")\n",
    "plt.plot(list(range(len(tracker.training_loss))), tracker.validation_loss, label=\"validation loss\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ab0d968002a578cf1e1aa041721a175249ba338f6da29efa5ef1a380c630376"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
